{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting information from universal dependency treebanks\n",
    "Using udapi and other tools to review content of treebanks.\n",
    "I've repeated some of the examples from http://udapi.github.io/tutorial/ and from http://udapi.github.io/slides.pdf using the Turkish universal dependencies *.conllu file.  I don't include the file itself, but you can obtain this or others from http://universaldependencies.org.  \n",
    "\n",
    "I've also included an example of my own where I use the structure provided by udapi to do a custom report without writing my own Block within the udapi architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-17 16:06:37,570 [   INFO] execute - No reader specified, using read.Conllu\n",
      "2018-05-17 16:06:37,570 [   INFO] execute -  ---- ROUND ----\n",
      "2018-05-17 16:06:37,570 [   INFO] execute - Executing block Conllu\n",
      "2018-05-17 16:06:38,531 [   INFO] execute - Executing block TextModeTrees\n",
      "# sent_id = mst-0003\u001b[m\n",
      "# text = Sanal parçacıklarsa bunların hiçbirini yapamazlar.\u001b[m\n",
      "─┮\u001b[m\n",
      " │   ╭─╼ \u001b[33mSanal\u001b[0m \u001b[31mADJ\u001b[0m \u001b[34mamod\u001b[0m\u001b[m\n",
      " │ ╭─┾ \u001b[33mparçacıklar\u001b[0m \u001b[31mNOUN\u001b[0m \u001b[34mcsubj\u001b[0m\u001b[m\n",
      " │ │ ╰─╼ \u001b[33msa\u001b[0m \u001b[31mAUX\u001b[0m \u001b[34mcop\u001b[0m\u001b[m\n",
      " │ │ ╭─╼ \u001b[33mbunların\u001b[0m \u001b[31mPRON\u001b[0m \u001b[34mnmod:poss\u001b[0m\u001b[m\n",
      " │ ┢─┶ \u001b[33mhiçbirini\u001b[0m \u001b[31mPRON\u001b[0m \u001b[34mobj\u001b[0m\u001b[m\n",
      " ╰─┾ \u001b[33myapamazlar\u001b[0m \u001b[31mVERB\u001b[0m \u001b[34mroot\u001b[0m\u001b[m\n",
      "   ╰─╼ \u001b[33m.\u001b[0m \u001b[31mPUNCT\u001b[0m \u001b[34mpunct\u001b[0m\u001b[m\n",
      "\u001b[m\n",
      "# sent_id = mst-0004\u001b[m\n",
      "# text = Ona her şeyimi verdim.\u001b[m\n",
      "─┮\u001b[m\n",
      " │ ╭─╼ \u001b[33mOna\u001b[0m \u001b[31mPRON\u001b[0m \u001b[34mobl\u001b[0m\u001b[m\n",
      " │ ┢─┮ \u001b[33mher\u001b[0m \u001b[31mDET\u001b[0m \u001b[34mobj\u001b[0m\u001b[m\n",
      " │ │ ╰─╼ \u001b[33mşeyimi\u001b[0m \u001b[31mNOUN\u001b[0m \u001b[34mcompound\u001b[0m\u001b[m\n",
      " ╰─┾ \u001b[33mverdim\u001b[0m \u001b[31mVERB\u001b[0m \u001b[34mroot\u001b[0m\u001b[m\n",
      "   ╰─╼ \u001b[33m.\u001b[0m \u001b[31mPUNCT\u001b[0m \u001b[34mpunct\u001b[0m\u001b[m\n",
      "\u001b[m\n",
      "# sent_id = mst-0006\u001b[m\n",
      "# text = Karşısında, pantolonu dizlerine dek ıslak, önlük torbası ham eriklerle \u001b[mdolu İbrahim dikiliyordu.\u001b[m\n",
      ":\u001b[K"
     ]
    }
   ],
   "source": [
    "# Use of udapy - an API for universal dependencies. \n",
    "# See http://udapi.github.io for more information.\n",
    "# To install use: $ pip3 install --user --upgrade udapi\n",
    "\n",
    "# Report multi-word tokens from Turkish.\n",
    "# Both methods word achieve the same result.\n",
    "#!cat UD_Turkish-IMST/tr_imst-ud-train.conllu | udapy -T | less -R\n",
    "!udapy -T < UD_Turkish-IMST/tr_imst-ud-train.conllu | less -R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-17 16:14:58,145 [   INFO] execute - No reader specified, using read.Conllu\n",
      "2018-05-17 16:14:58,145 [   INFO] execute -  ---- ROUND ----\n",
      "2018-05-17 16:14:58,145 [   INFO] execute - Executing block Conllu\n",
      "2018-05-17 16:14:59,174 [   INFO] execute - Executing block Eval\n",
      "  29 ise CCONJ\n",
      "  10 Hadi INTJ\n",
      "   5 ya INTJ\n",
      "   4 Aman INTJ\n",
      "   3 tabi INTJ\n",
      "   3 of INTJ\n",
      "   3 hadi INTJ\n",
      "   3 a INTJ\n",
      "   3 Yahu INTJ\n",
      "   2 haydi INTJ\n",
      "   2 ha INTJ\n",
      "   2 Eee INTJ\n",
      "   1 yo INTJ\n",
      "   1 yazık INTJ\n",
      "   1 sakın INTJ\n",
      "   1 hah INTJ\n",
      "   1 be INTJ\n",
      "   1 abi NOUN\n",
      "   1 Yoo INTJ\n",
      "   1 Yo INTJ\n",
      "   1 Ulan INTJ\n",
      "   1 Oh INTJ\n",
      "   1 Hey INTJ\n",
      "   1 Haydi INTJ\n",
      "   1 Eyvah INTJ\n",
      "   1 Ee INTJ\n",
      "   1 E INTJ\n",
      "   1 Aaa INTJ\n",
      "   1 A INTJ\n"
     ]
    }
   ],
   "source": [
    "# Now we try a query.\n",
    "!udapy util.Eval node='if node.deprel == \"discourse\": print(node.form, node.upos)' < UD_Turkish-IMST/tr_imst-ud-train.conllu > disc.txt\n",
    "!cat disc.txt | sort | uniq -c | sort -rn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-17 16:27:03,405 [   INFO] execute - No reader specified, using read.Conllu\n",
      "2018-05-17 16:27:03,405 [   INFO] execute -  ---- ROUND ----\n",
      "2018-05-17 16:27:03,405 [   INFO] execute - Executing block Conllu\n",
      "2018-05-17 16:27:04,375 [   INFO] execute - Executing block Wc\n",
      "    3685 trees\n",
      "   38082 words\n",
      "    1087 multi-word tokens\n",
      "   36970 tokens\n"
     ]
    }
   ],
   "source": [
    "# Word counts\n",
    "!udapy util.Wc < UD_Turkish-IMST/tr_imst-ud-train.conllu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-17 16:43:08,114 [   INFO] execute - No reader specified, using read.Conllu\n",
      "2018-05-17 16:43:08,114 [   INFO] execute -  ---- ROUND ----\n",
      "2018-05-17 16:43:08,114 [   INFO] execute - Executing block Conllu\n",
      "2018-05-17 16:43:09,087 [   INFO] execute - Executing block See\n",
      "node.multiword_token != None\n",
      "matches 2199 out of 38082 nodes (5.8%) in 884 out of 3685 trees (24.0%)\n",
      "=== dir (3 values) ===\n",
      "          right  1346  61% delta=+27%\n",
      "           left   569  25% delta=-30%\n",
      "           root   284  12% delta= +3%\n",
      "=== edge (44 values) ===\n",
      "              1  1071  48% delta=+28%\n",
      "             -2   299  13% delta= +3%\n",
      "              0   284  12% delta= +3%\n",
      "              2   134   6% delta= +0%\n",
      "             -3   129   5% delta= +0%\n",
      "=== depth (11 values) ===\n",
      "              2   589  26% delta= -5%\n",
      "              3   502  22% delta= -4%\n",
      "              4   379  17% delta= +1%\n",
      "              1   284  12% delta= +3%\n",
      "              5   229  10% delta= +2%\n",
      "=== children (11 values) ===\n",
      "              0  1150  52% delta= -5%\n",
      "              1   338  15% delta= -3%\n",
      "              2   269  12% delta= +1%\n",
      "              3   160   7% delta= +0%\n",
      "              4   150   6% delta= +3%\n",
      "=== siblings (10 values) ===\n",
      "              0   773  35% delta= +6%\n",
      "              1   517  23% delta= +2%\n",
      "              2   356  16% delta= -3%\n",
      "              3   266  12% delta= -2%\n",
      "              4   151   6% delta= -1%\n",
      "=== p_upos (13 values) ===\n",
      "           NOUN   974  44% delta=+12%\n",
      "            ADJ   356  16% delta= +6%\n",
      "           VERB   338  15% delta=-25%\n",
      "         <ROOT>   284  12% delta= +3%\n",
      "           PRON    57   2% delta= +1%\n",
      "=== p_lemma (937 values) ===\n",
      "         <ROOT>   284  12% delta= +3%\n",
      "            yok    35   1% delta= +0%\n",
      "             ol    34   1% delta= -1%\n",
      "            var    28   1% delta= +0%\n",
      "             de    27   1% delta= -1%\n",
      "=== c_upos (14 values) ===\n",
      "            ADP   581  21% delta=+17%\n",
      "          PUNCT   475  17% delta= -2%\n",
      "           NOUN   468  17% delta=-11%\n",
      "            AUX   465  17% delta=+15%\n",
      "           VERB   172   6% delta= -7%\n",
      "=== form (866 values) ===\n",
      "             ki   200   9% delta= +8%\n",
      "             li    76   3% delta= +3%\n",
      "             lı    60   2% delta= +2%\n",
      "            dır    45   2% delta= +1%\n",
      "            dir    39   1% delta= +1%\n",
      "=== lemma (608 values) ===\n",
      "              i   501  22% delta=+21%\n",
      "             ki   228  10% delta= +9%\n",
      "             li   170   7% delta= +7%\n",
      "              _    72   3% delta= +3%\n",
      "             ce    43   1% delta= +1%\n",
      "=== upos (9 values) ===\n",
      "            ADP   628  28% delta=+24%\n",
      "           NOUN   546  24% delta= -2%\n",
      "            AUX   501  22% delta=+21%\n",
      "            ADJ   276  12% delta= +2%\n",
      "           VERB   123   5% delta=-13%\n",
      "=== deprel (23 values) ===\n",
      "           case   610  27% delta=+23%\n",
      "            cop   497  22% delta=+21%\n",
      "           root   284  12% delta= +3%\n",
      "           nmod   234  10% delta= +4%\n",
      "           conj   148   6% delta= +0%\n",
      "=== feats_split (42 values) ===\n",
      "       Person=3  1366  19% delta= +4%\n",
      "    Number=Sing  1337  18% delta= +4%\n",
      "       Case=Nom   703   9% delta= +2%\n",
      "    Aspect=Perf   611   8% delta= +3%\n",
      "              _   583   8% delta= -3%\n"
     ]
    }
   ],
   "source": [
    "# More advanced statistics.\n",
    "#!udapy util.See node='node.is_nonprojective()' < UD_Turkish-IMST/tr_imst-ud-train.conllu\n",
    "\n",
    "!udapy util.See node='node.multiword_token != None' < UD_Turkish-IMST/tr_imst-ud-train.conllu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom reporting using udapi\n",
    "More complex reporting requires either that we write a class that inherits from Block (udapi.core.block) or that we open the file we want to report on using Document (udapi.core.document) and access directly the node, mwt, tree structues needed.  This later approach is a bit of a hack, or more generously, a rapid prototyping strategy.  \n",
    "\n",
    "Here is an example reporting on the Turkish *.conllu files using udapi tools.  \n",
    "\n",
    "We were looking at the frequecy of use of multiword tokens (MWTs) in Turkish for comparison with how we are coding our own agglinative languages of the Amazon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of sentences: 3685\n",
      "\n",
      "# tokens: 226597\n",
      "# MWTs: 1087\n",
      "proption MWTs: 0.004797062626601411\n",
      "MWT: [('yoktu', 16), ('önemli', 15), ('vardı', 9), ('arasındaki', 9), ('önceki', 9), ('hafifçe', 8), ('vardır', 8), ('vadeli', 8), ('yoksa', 7), ('gibiydi', 7), ('yoktur', 7), ('sessiz', 6), ('dolarlık', 6), ('altındaki', 5), ('üzerindeki', 5), ('?edir', 5), ('saatlik', 4), ('içindeki', 4), ('yanındaki', 4), ('doluydu', 4), ('Katana', 4), ('benim', 4), ('rahatça', 4), ('zamanki', 4), ('demektir', 4), ('adlı', 4), ('olanlar', 4), ('sağlıklı', 3), ('?eymiş', 3), ('iyice', 3), ('tarihli', 3), ('ürkütücü', 3), ('sebzedir', 3), ('zordur', 3), ('aptalca', 3), ('önümüzdeki', 3), ('Tehlikeli', 3), ('imkansızdı', 3), ('elbiseli', 3), ('saçlı', 3), ('elindeki', 3), ('buydu', 3), ('yıldır', 3), ('günkü', 3), ('yıllardır', 3), ('buradaki', 3), ('gelene', 3), ('Benim', 3), ('Yoksa', 3), ('yavaşça', 3)]\n",
      "\n",
      "First morpheme:\n",
      "lemma1: [('yok', 34), ('var', 21), ('önem', 19), ('ol', 13), ('gibi', 12), ('ben', 11), ('ara', 11), ('ne', 10), ('önce', 10), ('hafif', 8), ('içinde', 8), ('ses', 8), ('iyi', 8), ('vade', 8), ('yan', 8), ('o', 8), ('yıl', 8), ('kat', 7), ('bura', 6), ('gel', 6), ('zorun', 6), ('dolu', 6), ('et', 6), ('el', 6), ('zaman', 6), ('dolar', 6), ('üzer', 6), ('ad', 6), ('biz', 5), ('süreç', 5), ('saat', 5), ('tarih', 5), ('yaşa', 5), ('nere', 5), ('ora', 5), ('ön', 5), ('altı', 5), ('öyle', 5), ('rahat', 5), ('bu', 5), ('sık', 4), ('gün', 4), ('iç', 4), ('ürküt', 4), ('zor', 4), ('aptal', 4), ('tehlike', 4), ('kenar', 4), ('de', 4), ('yavaş', 4)]\n",
      "\n",
      "upos1: Counter({'NOUN': 546, 'ADJ': 271, 'VERB': 123, 'PRON': 52, 'ADV': 35, 'ADP': 22, 'PROPN': 20, 'NUM': 18})\n",
      "\n",
      "deprel1: Counter({'root': 284, 'nmod': 234, 'conj': 142, 'amod': 111, 'obl': 79, 'compound': 40, 'nmod:poss': 29, 'obj': 29, 'nsubj': 26, 'flat': 25, 'ccomp': 20, 'acl': 18, 'case': 11, 'advmod': 8, 'nummod': 8, 'compound:lvc': 7, 'csubj': 5, 'compound:redup': 5, 'cc': 3, 'advmod:emph': 1, 'det': 1, 'fixed': 1})\n",
      "\n",
      "Subsequent morphemes:\n",
      "lemma: [('i', 501), ('ki', 228), ('li', 170), ('_', 72), ('ce', 43), ('lik', 36), ('siz', 30), ('ci', 26), ('dir', 6)]\n",
      "\n",
      "upos: Counter({'ADP': 606, 'AUX': 501, 'ADJ': 5})\n",
      "\n",
      "deprel: Counter({'case': 599, 'cop': 497, 'conj': 6, 'amod': 5, 'compound': 3, 'flat': 2})\n"
     ]
    }
   ],
   "source": [
    "# Use conllu more directly with udapi structure.\n",
    "from udapi.core.document import Document\n",
    "from collections import Counter\n",
    "\n",
    "filename = 'UD_Turkish-IMST/tr_imst-ud-train.conllu'\n",
    "outfile = open('Turkish-mwt.txt','wt')\n",
    "\n",
    "count_upos = Counter()\n",
    "count_upos1 = Counter()\n",
    "count_deprel = Counter()\n",
    "count_deprel1 = Counter()\n",
    "count_lemma1 = Counter()\n",
    "count_lemma = Counter()\n",
    "count_mwt = Counter()\n",
    "count_tokens = 0\n",
    "\n",
    "document = Document()\n",
    "document.load_conllu(filename=filename)\n",
    "document.bundles\n",
    "print('number of sentences:', len(document.bundles))\n",
    "# Process through all trees. \n",
    "for sentence in document.bundles:\n",
    "    # Each sentence has unique presentation in monolingual dependency graph.\n",
    "    # So no need to specify zone or iterate on zone.\n",
    "    tree = sentence.get_tree()\n",
    "    count_tokens += len(tree.get_sentence())\n",
    "    # Get list of all multiword tokens.\n",
    "    for mwt in tree.multiword_tokens:\n",
    "        #print(mwt.form)\n",
    "        token = [mwt.form]\n",
    "        count_mwt[mwt.form] += 1\n",
    "\n",
    "        for i, word in enumerate(mwt.words):\n",
    "            token += ['|', word.form, word.lemma, word.upos, word.deprel]\n",
    "            if i == 0:\n",
    "                count_lemma1[word.lemma] += 1\n",
    "                count_deprel1[word.deprel] += 1\n",
    "                count_upos1[word.upos] += 1\n",
    "            else:\n",
    "                count_lemma[word.lemma] += 1\n",
    "                count_deprel[word.deprel] += 1\n",
    "                count_upos[word.upos] += 1\n",
    "            \n",
    "        print(token, file=outfile)\n",
    "        \n",
    "outfile.close()\n",
    "print('\\n# tokens:', count_tokens)\n",
    "count_MWTs = sum(count_mwt.values())\n",
    "print('# MWTs:', count_MWTs)\n",
    "print('proption MWTs:', count_MWTs/count_tokens)\n",
    "print('MWT:', count_mwt.most_common(50))\n",
    "print('\\nFirst morpheme:')\n",
    "print('lemma1:', count_lemma1.most_common(50))\n",
    "print('\\nupos1:', count_upos1)\n",
    "print('\\ndeprel1:', count_deprel1)\n",
    "print('\\nSubsequent morphemes:')\n",
    "print('lemma:', count_lemma.most_common(50))\n",
    "print('\\nupos:', count_upos)\n",
    "print('\\ndeprel:', count_deprel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
